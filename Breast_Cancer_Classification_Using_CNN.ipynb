{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VuxRAT1YlOe73ynCnrtcM3P8ULXFuoko",
      "authorship_tag": "ABX9TyNzziqMjta3OrH5qLuXlRIZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arbabyounis46/Project_Breast_Cancer_Classification/blob/main/Breast_Cancer_Classification_Using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Drive to Use Dataset"
      ],
      "metadata": {
        "id": "OgyTKXHwHzKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28BLdrlAGrA6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing The Libraries"
      ],
      "metadata": {
        "id": "HoAoGwgmIP_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import os  # For file and directory operations\n",
        "import numpy as np  # For numerical operations\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "\n",
        "import tensorflow as tf  # For building and training deep learning models\n",
        "\n",
        "from sklearn.metrics import *  # For evaluating model performance\n",
        "\n",
        "import matplotlib.pyplot as plt  # For data visualization\n",
        "import seaborn as sns  # For enhanced data visualization\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For image augmentation\n",
        "from tensorflow.keras import layers, models  # For building deep learning models\n",
        "\n",
        "# Enable data loading in parallel to improve performance\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# Load the CSV file containing information about the data folds\n",
        "folds_data = pd.read_csv('/content/drive/MyDrive/Data Set/Folds.csv')\n",
        "\n",
        "# Specify the path where images are stored\n",
        "images_path = '/content/drive/MyDrive/Data Set/BreaKHis_v1'\n",
        "\n",
        "# Define tumor classes for classification\n",
        "tumor_classes = ['benign', 'malignant']\n",
        "\n",
        "# The code below this would likely involve data preprocessing, model building, and training.\n"
      ],
      "metadata": {
        "id": "37LnPRuJIQOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing the Duplicate Values in the CSV File"
      ],
      "metadata": {
        "id": "7etqc0RjItnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate filenames\n",
        "duplicate_filename_count = folds_data['filename'].duplicated().sum()\n",
        "print(f'Number of duplicate filenames: {duplicate_filename_count}')\n",
        "\n",
        "# Remove duplicate rows based on the 'filename' column to retain only unique entries\n",
        "folds_data = folds_data.drop_duplicates(subset='filename', keep='first')\n",
        "\n",
        "# Print the updated shape of the DataFrame\n",
        "print(f'Updated shape of the DataFrame: {folds_data.shape}')\n"
      ],
      "metadata": {
        "id": "3tkhOJhXItxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the 'filename' column to 'path'\n",
        "folds_data = folds_data.rename(columns={'filename': 'path'})\n",
        "\n",
        "# Extract and assign labels from the path (assuming the label is the 4th part of the path)\n",
        "folds_data['label'] = folds_data['path'].apply(lambda x: x.split('/')[3])\n",
        "\n",
        "# Convert labels to integer indices based on the defined tumor_classes list\n",
        "folds_data['label_int'] = folds_data['label'].apply(lambda x: tumor_classes.index(x))\n",
        "\n",
        "# Extract and assign file names from the path\n",
        "folds_data['file_name'] = folds_data['path'].apply(lambda x: x.split('/')[-1])\n",
        "\n",
        "# Update the 'path' column to include the full image folder path\n",
        "folds_data['path'] = folds_data['path'].apply(lambda x: images_path + x)\n",
        "\n",
        "# Display the first three rows of the DataFrame to verify the changes\n",
        "folds_data.head(3)\n"
      ],
      "metadata": {
        "id": "QzInuyqxJCRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining colors for tumor classes\n",
        "ax = sns.displot(\n",
        "    data=folds_data,\n",
        "    x='label',\n",
        "    hue='label',\n",
        "    palette={'benign': 'lightgreen', 'malignant': 'lightpink'}  # Changed colors\n",
        ")\n",
        "\n",
        "# Displaying the count of each label\n",
        "print('Count of Benign    : ', folds_data[folds_data['label'] == 'benign']['label'].count())\n",
        "print('Count of Malignant : ', folds_data[folds_data['label'] == 'malignant']['label'].count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Rw6kwcDOJU1K",
        "outputId": "bdafdca7-84fb-4b70-fb5d-7574f12d2276"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sns' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-acd1cf24b1dd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Defining colors for tumor classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m ax = sns.displot(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolds_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove 600 samples from the dataset for testing (300 per class)\n",
        "test_data = folds_data.groupby('label').sample(n=300)\n",
        "train_data = folds_data.drop(test_data.index).reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)\n",
        "\n",
        "# Split training and validation sets\n",
        "validation_data = train_data.sample(frac=0.2)\n",
        "train_data = train_data.drop(validation_data.index).reset_index(drop=True)\n",
        "validation_data = validation_data.reset_index(drop=True)\n",
        "\n",
        "# Assign set labels and combine data\n",
        "test_data['set'] = 'test'\n",
        "train_data['set'] = 'train'\n",
        "validation_data['set'] = 'valid'\n",
        "combined_data = pd.concat([train_data, validation_data, test_data])\n",
        "\n",
        "# Set up the figure with a column of three subplots\n",
        "fig, axes = plt.subplots(3, 1, figsize=(8, 15))\n",
        "\n",
        "# Plot each distribution with different colors and assign to specific axes\n",
        "sns.histplot(data=train_data, x='label', color='teal', ax=axes[0])\n",
        "axes[0].set_title('Training Set')\n",
        "\n",
        "sns.histplot(data=validation_data, x='label', color='purple', ax=axes[1])\n",
        "axes[1].set_title('Validation Set')\n",
        "\n",
        "sns.histplot(data=test_data, x='label', color='orange', ax=axes[2])\n",
        "axes[2].set_title('Test Set')\n",
        "\n",
        "# Show the plots in a vertical layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print counts for each set\n",
        "print('Training set')\n",
        "print(train_data['label'].value_counts())\n",
        "\n",
        "print('\\nValidation set')\n",
        "print(validation_data['label'].value_counts())\n",
        "\n",
        "print('\\nTest set')\n",
        "print(test_data['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "dOVUkXltKQQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsample the training dataset to balance the classes\n",
        "max_count = np.max(train_data['label'].value_counts())\n",
        "train_data = train_data.groupby('label').sample(n=max_count, replace=True).reset_index(drop=True)\n",
        "\n",
        "# Plot distribution after upsampling\n",
        "ax = sns.displot(data=train_data, x='label', color='mediumslateblue')\n",
        "ax.set(title='Upsampled Training Set')\n",
        "plt.show()\n",
        "\n",
        "# Display counts to verify upsampling\n",
        "print(train_data['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "2qImsdLpKTzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'label_int' to string type for categorical class mode\n",
        "train_data['label_int'] = train_data['label_int'].astype(str)\n",
        "validation_data['label_int'] = validation_data['label_int'].astype(str)\n",
        "\n",
        "# Data augmentation setup with fewer parameters for simplicity\n",
        "train_image_gen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Use a simpler validation generator with rescaling only\n",
        "validation_image_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Training data generator setup\n",
        "train_data_gen = train_image_gen.flow_from_dataframe(\n",
        "    dataframe=train_data,\n",
        "    directory='',\n",
        "    x_col='path',\n",
        "    y_col='label_int',\n",
        "    target_size=(210, 210),\n",
        "    batch_size=64,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "# Validation data generator setup\n",
        "validation_data_gen = validation_image_gen.flow_from_dataframe(\n",
        "    dataframe=validation_data,\n",
        "    directory='',\n",
        "    x_col='path',\n",
        "    y_col='label_int',\n",
        "    target_size=(210, 210),\n",
        "    batch_size=64,\n",
        "    class_mode='sparse'\n",
        ")\n"
      ],
      "metadata": {
        "id": "3cJk6LU5KmYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Model Architecture"
      ],
      "metadata": {
        "id": "TV9VS2yiNLIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# First convolutional block\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(210, 210, 3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "# Second convolutional block\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "# Third convolutional block\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "# Fourth convolutional block\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.35))\n",
        "\n",
        "# Flatten and fully connected layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(2, activation='softmax'))  # Output layer for 2 classes\n",
        "\n",
        "# Print model summary to verify structure\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "7UTlV-d7NLQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BptjVNL5Kt5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with Adam optimizer, sparse categorical cross-entropy loss, and accuracy metric\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary to verify the final architecture\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "rgyuIWwOKuEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data_generator,        # Training data generator\n",
        "    epochs=20,                   # Number of epochs (adjust as needed)\n",
        "    validation_data=validation_data_generator,  # Validation data generator\n",
        "    steps_per_epoch=len(train_data_generator),  # Number of steps per epoch\n",
        "    validation_steps=len(validation_data_generator),  # Number of validation steps per epoch\n",
        "    verbose=1                    # Verbosity mode for training progress output\n",
        ")\n",
        "\n",
        "# Save the trained model if needed\n",
        "model.save('custom_cnn_model_breast_cancer.h5')\n"
      ],
      "metadata": {
        "id": "IxWYd7aKNzJo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}